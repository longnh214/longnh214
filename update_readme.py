import requests
from bs4 import BeautifulSoup
import re
import os
from datetime import datetime, timezone, timedelta


BLOG_URL = "https://longnh214.github.io/"

README_PATH = "README.md"

KST = timezone(timedelta(hours=9))


def get_latest_posts(url, num_posts=5):
    """
    ë¸”ë¡œê·¸ URLì—ì„œ ìµœì‹  í¬ìŠ¤íŠ¸ ëª©ë¡(ì œëª©, ë§í¬, ë‚ ì§œ)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        response = requests.get(url)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"ë¸”ë¡œê·¸ ì ‘ì† ì˜¤ë¥˜: {e}")
        return []

    soup = BeautifulSoup(response.text, 'html.parser')
    posts = []
    
    post_cards = soup.find_all('article', class_='card-wrapper card')

    for card in post_cards:
        link_tag = card.find('a', class_='post-preview')
        link = link_tag.get('href') if link_tag else None

        if link and not link.startswith('http'):
            link = os.path.join(BLOG_URL, link.lstrip('/')).replace('\\', '/')

        title_tag = card.find('h1', class_='card-title')
        title = title_tag.get_text(strip=True) if title_tag else None

        date_tag = card.find('time')
        date_str = None
        if date_tag and 'data-ts' in date_tag.attrs:
            timestamp = int(date_tag['data-ts'])
            # ğŸ‘‰ KSTë¡œ ë³€í™˜í•˜ì—¬ ë‚ ì§œ í‘œì‹œ
            date_str = datetime.fromtimestamp(timestamp, tz=KST).strftime('%Y-%m-%d')
        elif date_tag:
            date_str = date_tag.get_text(strip=True)

        if title and link and date_str and link.startswith(BLOG_URL):
            if (title, link, date_str) not in posts:
                posts.append((title, link, date_str))
        
        if len(posts) >= num_posts:
            break
            
    return posts[:num_posts]


def update_readme(posts):
    """
    README.md íŒŒì¼ì˜ íŠ¹ì • ì„¹ì…˜ì„ ìµœì‹  í¬ìŠ¤íŠ¸ ëª©ë¡ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    ì œëª©ê³¼ ë‚ ì§œë¥¼ ì¡°í•©í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    try:
        with open(README_PATH, 'r', encoding='utf-8') as f:
            readme_content = f.read()
    except FileNotFoundError:
        print(f"ERROR: {README_PATH} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    start_marker = "---"
    end_marker = "---"

    if start_marker not in readme_content or end_marker not in readme_content:
        print(f"ERROR: {start_marker} ë˜ëŠ” {end_marker} ë§ˆì»¤ë¥¼ {README_PATH}ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("README.mdì— ë§ˆì»¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return

    new_posts_content = [
        f"- [{title}]({link}) [{date_str}]" for title, link, date_str in posts
    ]
    new_posts_text = "\n".join(new_posts_content)

    updated_readme = re.sub(
        f'{start_marker}.*?{end_marker}',
        f'{start_marker}\n{new_posts_text}\n{end_marker}',
        readme_content,
        flags=re.DOTALL
    )

    if updated_readme == readme_content:
        print("README.md ë‚´ìš©ì— ë³€ê²½ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. ì—…ë°ì´íŠ¸ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    with open(README_PATH, 'w', encoding='utf-8') as f:
        f.write(updated_readme)
    print(f"{len(posts)}ê°œì˜ ìµœì‹  í¬ìŠ¤íŠ¸ë¡œ {README_PATH} ì—…ë°ì´íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    print("ìµœì‹  ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹œì‘...")
    latest_posts = get_latest_posts(BLOG_URL, num_posts=5)

    if latest_posts:
        print("ìµœì‹  í¬ìŠ¤íŠ¸:", latest_posts)
        update_readme(latest_posts)
    else:
        print("ìµœì‹  í¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. README.mdë¥¼ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
